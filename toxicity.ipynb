{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a236069-f215-402e-b1d7-23055f6ac9ac",
   "metadata": {},
   "source": [
    "<h1> Comment Toxicity Detection </h1>\n",
    "<p> In this project I will create a deep neural network which can hopefully accurately detect whether a comment made online was \"toxic\" or not. There are 6 categorical values that a comment can have, being \"toxic\", \"severe toxic\", \"obscene\", \"threat\", \"insult\" and \"identity hate\". </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c94de-2284-4076-a05f-7d2f08ecfeaa",
   "metadata": {},
   "source": [
    "<h3> Importing libraries needed and the Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c6490d-633b-4375-8763-b8654dda991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic   \n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0  \\\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"./archive/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7f990-dc8d-4391-9ad3-4bf488103b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Data Preprocessing </h3>\n",
    "\n",
    "<p> I will start off by preprocessing the text data. This includes lower-casing, removing stop words, punctuation removal and then using TextVectorization, which converts words to integers to be used by the model. I will also do other steps like splitting training and testing data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619e232f-8cdb-49e5-bc90-49ac7895c074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 18:15:13.395363: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  591,   140,    59, ...,     0,     0,     0],\n",
       "       [    1,   145,  2465, ...,     0,     0,     0],\n",
       "       [  358,   378,    19, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32414,  7384,   314, ...,     0,     0,     0],\n",
       "       [   27,   477,    13, ...,     0,     0,     0],\n",
       "       [   27,     2,    66, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(s):\n",
    "    return ' '.join(word for word in s.split() if word not in stop)\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(remove_stop_words)\n",
    "\n",
    "\n",
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values\n",
    "\n",
    "MAX_FEATURES = 200000 #number of words in the vocab\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int', standardize='lower_and_strip_punctuation')\n",
    "vectorizer.adapt(X.values)\n",
    "vectorized_text = vectorizer(X.values)\n",
    "vectorized_text #each integer represents a word in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc76b656-9a2f-48b6-b34b-c594ef7bdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache() #improve performance\n",
    "dataset = dataset.shuffle(160000) # prevent overfitting in case data is arranged in specific way\n",
    "dataset = dataset.batch(16) # each batch has 16 data points\n",
    "dataset = dataset.prefetch(8) # while model works on one batch, tensorflow can preload others so theres no bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6abd251-017a-414e-85fb-fbc808e3b25c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   6,  387,    2, ...,    0,    0,    0],\n",
       "        [1686,  882,  505, ...,    0,    0,    0],\n",
       "        [  19, 1608,   80, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1584, 7438, 1381, ...,    0,    0,    0],\n",
       "        [3321,    4, 3321, ...,    0,    0,    0],\n",
       "        [1140,  356,   12, ...,    0,    0,    0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next() #view the first batch that will be fed into training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e65b08-cd45-4d76-ae7e-f14e1ea95708",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.take(int(len(dataset) * 0.7)) #take 70% of the data to use for training\n",
    "validation_data = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "testing_data = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4e81c-bfaf-4575-8ebb-5ed8d4df66f2",
   "metadata": {},
   "source": [
    "<h3> Create and Train Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3eb8285-5a28-48be-bec0-b0a45c3f76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50683dcc-60b2-405d-a56d-e33360159a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#create embedding layer which is able to capture relationship between words. Words closer together have more similar meaning.\n",
    "#might have been better if i had used Word2Vec but i wanted to try creating my own Embedding Layer\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "#bidirectional lstm is important for nlp - eg phrases like \"i don't hate you\". need to remember earlier words and consider both directions. \n",
    "#lstm addresses issues from traditional rnn like exploading/vanishing gradient problem.\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "#feature extraction\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#since final data for 6 categories need to be between 0 and 1\n",
    "model.add(Dense(6, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfe6099-582e-4c86-afb9-ac612c38df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"BinaryCrossentropy\", optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c28c4d28-b800-49ff-b971-8bf5bf279e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8dc30f-640c-45c2-a9a3-5956a575d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6981/6981 [==============================] - 1713s 245ms/step - loss: 0.0623 - val_loss: 0.0477\n",
      "Epoch 2/3\n",
      "6981/6981 [==============================] - 1650s 236ms/step - loss: 0.0452 - val_loss: 0.0398\n",
      "Epoch 3/3\n",
      "6981/6981 [==============================] - 1618s 232ms/step - loss: 0.0394 - val_loss: 0.0350\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # which metric to monitor.\n",
    "    min_delta=0,  # minimum change to qualify as an improvement.\n",
    "    patience=1,  # number of epochs with no improvement to stop training.\n",
    "    verbose=1,  # print messages.\n",
    "    restore_best_weights=True  # restore the best weights from the epoch with the best monitored metric.\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(training_data, epochs = 3, validation_data = validation_data, callbacks = early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de916e8-9ace-432b-a9b5-0a547a251e31",
   "metadata": {},
   "source": [
    "<h3> Try making some predictions </h3>\n",
    "\n",
    "<p> Using the example below - the text is detected as toxic, obscene and  an insult. However, it's not considered a threat, severely tocic or identity hate </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b80aee9-5fef-475a-b7c8-0bf3064bea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer(\"You suck! Balls!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6365ae-e176-4f0a-ad95-ac2456289969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 814ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False,  True, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(input_text, 0)) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbf3b92-49e8-4a88-9f38-99c70448e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb88c8-166c-4615-ac81-7bda7b867d21",
   "metadata": {},
   "source": [
    "<h3> Evaluating the Model's Performance </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ebba7f-1780-4896-9e21-c64594009ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "\n",
    "precision = Precision() #lower value shows fewer false positives\n",
    "recall = Recall() #lower value shows fewer false negatives\n",
    "accuracy = CategoricalAccuracy() # correct predictions / total predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3294137d-f8f4-4f78-9718-806af9cb7f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for batch in testing_data.as_numpy_iterator():\n",
    "    X_test_batch, y_test_batch = batch\n",
    "    \n",
    "    predict = model.predict(X_test_batch)\n",
    "    print(predict.shape)\n",
    "    y_test_batch = y_test_batch.flatten() #true values\n",
    "    predict = predict.flatten() #predicted values\n",
    "    \n",
    "    precision.update_state(y_test_batch, predict)\n",
    "    recall.update_state(y_test_batch, predict)\n",
    "    accuracy.update_state(y_test_batch, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d128936-d047-4f8f-a173-be132716c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8509753942489624, Recall:0.7661963701248169, Accuracy:0.49949848651885986\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision.result().numpy()}, Recall:{recall.result().numpy()}, Accuracy:{accuracy.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e01ef5-d74d-4877-a384-b8f19ea392c1",
   "metadata": {},
   "source": [
    "<p> The precision is a higher than recall, which means the model is making a lot of false negatives. While trying the model out, I noticed that the model rarely predicts categories like \"threat\" since they do not occur frequently in the training dataset. A possible improvement would be to assign a higher weight to minority categories. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ef5db-5564-414c-961d-feeeb22743f6",
   "metadata": {},
   "source": [
    "<h3> Sharing Model using Gradio </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ae9048-a21b-4f69-99e9-5b14a9ed516e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (3.32.0)\n",
      "Requirement already satisfied: jinja2 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: aiofiles in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: altair>=4.2.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: fastapi in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.95.2)\n",
      "Requirement already satisfied: ffmpy in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.2.5)\n",
      "Requirement already satisfied: httpx in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.14.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (3.8.14)\n",
      "Requirement already satisfied: pandas in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: pillow in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (9.5.0)\n",
      "Requirement already satisfied: pydantic in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (1.10.8)\n",
      "Requirement already satisfied: pydub in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: python-multipart in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: semantic-version in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (2023.5.0)\n",
      "Requirement already satisfied: packaging in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (23.0)\n",
      "Requirement already satisfied: filelock in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from pandas->gradio) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: click>=7.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: certifi in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from httpx->gradio) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from httpx->gradio) (0.17.2)\n",
      "Requirement already satisfied: idna in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from matplotlib->gradio) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from requests->gradio) (1.26.15)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tanveersingh/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0791d76-115d-4e1b-ac7c-c5c31069a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3865a36d-6e9e-4010-8805-bb2acd931a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"toxicity.h5\")\n",
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "737d8bef-f304-4f64-b2ed-f68e58cf5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d80dfaa4-aab6-42a5-875e-b2a080259362",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d5b27f-3970-444a-8782-2cbf29826c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a5cab15-b5b4-486e-9b20-e902072d2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: count, dtype: int64\n",
      "obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: count, dtype: int64\n",
      "threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: count, dtype: int64\n",
      "insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: count, dtype: int64\n",
      "identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[2:]:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ecef5-7ca0-4ede-ad9f-7ff1fcb1174d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
